{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The redshift evolution of the BBH merger rate: \"a weighty matter\"\n",
    "\n",
    "## Notebook to reproduce values that are quoted in the text of the paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################\n",
    "## Imports\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "from astropy.table import Table, Column\n",
    "import astropy.units as u\n",
    "from astropy import constants as const\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Chosen cosmology \n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy.cosmology import z_at_value\n",
    "\n",
    "# Extra python functions\n",
    "import HelperFunctions as func\n",
    "\n",
    "######################################\n",
    "## locations\n",
    "save_loc    =  '../plots/'\n",
    "data_dir    = '../output/'\n",
    "# This will be put in front of the name for every figure we safe \n",
    "sim_save_str = 'N1e7_'\n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=True)\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,25,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=MEDIUM_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "######################################\n",
    "## Widescreen jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read your data\n",
    "\n",
    "the function `read_data` is part of `HelperFunctions.py` and reads the hdf5 file containing the BBH population data and merger rates \n",
    "\n",
    "The Bool \"DCO_mask\" filters for BBHs:  \n",
    "1. with an inspiral time that is less than the age of the Universe\n",
    "2. excludes systems that experienced a CE from a HG donor (i.e. the flag `Optimistic_CE == False`)\n",
    "3. excludes systems that experienced RLOF immediately following a CE (i.e. the flag `Immediate_RLOF>CE == False`)\n",
    "\n",
    "In other words, we treat 2. and 3. as stellar mergers and exclude them from the rest of our analysis\n",
    "\n",
    "## & Filter your data\n",
    "Select merging BBHs using the `DCO_mask`, and aditionally exclude systems that evolve Chemically homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output//COMPAS_Output_wWeights.h5\n",
      "<Table length=4342215>\n",
      "        name          dtype \n",
      "-------------------- -------\n",
      "      CE_Event_Count  uint32\n",
      "    Coalescence_Time float64\n",
      "    Eccentricity@DCO float64\n",
      "   Immediate_RLOF>CE   uint8\n",
      "    MT_Donor_Hist(1) bytes17\n",
      "    MT_Donor_Hist(2) bytes17\n",
      "             Mass(1) float64\n",
      "             Mass(2) float64\n",
      "  Merges_Hubble_Time   uint8\n",
      " Metallicity@ZAMS(1) float64\n",
      "       Optimistic_CE   uint8\n",
      "      Recycled_NS(1)   uint8\n",
      "      Recycled_NS(2)   uint8\n",
      "                SEED  uint64\n",
      "   SemiMajorAxis@DCO float64\n",
      "     Stellar_Type(1)   int32\n",
      "     Stellar_Type(2)   int32\n",
      "                Time float64\n",
      "      mixture_weight float64\n",
      "  SemiMajorAxis@ZAMS float64\n",
      "        Mass@ZAMS(1) float64\n",
      "        Mass@ZAMS(2) float64\n",
      "              q_init float64\n",
      "Stellar_Type@ZAMS(1)   int32\n",
      "Stellar_Type@ZAMS(2)   int32\n",
      "              tDelay float64\n",
      "       M_moreMassive float64\n",
      "       M_lessMassive float64\n",
      "             q_final float64\n",
      "(2252487, 200) (2252487,)\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "## Reading file ##\n",
    "rate_key      = 'Rates_mu00.025_muz-0.05_alpha-1.77_sigma01.125_sigmaz0.05_zBinned'\n",
    "File_location = data_dir+'/COMPAS_Output_wWeights.h5'\n",
    "print(File_location)\n",
    "\n",
    "####################################################\n",
    "DCO, DCO_mask, redshifts, Average_SF_mass_needed, intrinsic_rate_density, intrinsic_rate_density_z0, = func.read_data(loc = File_location, rate_key = rate_key)\n",
    "\n",
    "DCO.info()\n",
    "\n",
    "##########################################################\n",
    "# Select merging BBHs w.o. CHE only\n",
    "##########################################################\n",
    "nonCHE_bool         = DCO['Stellar_Type@ZAMS(1)'] != 16\n",
    "rate_nonCHE_bool    = DCO['Stellar_Type@ZAMS(1)'][DCO_mask] != 16\n",
    "\n",
    "# Filter both the BBH table and the intrinsic rate data\n",
    "merging_BBH         = DCO[DCO_mask * nonCHE_bool]\n",
    "Red_intr_rate_dens  = intrinsic_rate_density[rate_nonCHE_bool, :]\n",
    "\n",
    "print(np.shape(Red_intr_rate_dens), np.shape(merging_BBH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the median separation at DCO formation for the CE vs the stable RLOF channel?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE systems 33967.34662725864\n",
      "stable RLOF systems 17937.32230749049\n",
      "\n",
      "Weighted median separation at DCO formation, for BBH merging at z=0: 22.774648199932038 Rsun\n",
      "for CE channel: 14.05121953572752 Rsun\n",
      "for stable RLOF channel: 31.041092341716507 Rsun\n",
      "\n",
      "Weighted median separation at DCO formation, for BBH as detected by a perfect detector 8.16800446555253 Rsun\n",
      "for CE channel: 7.337725321668436 Rsun\n",
      "for stable RLOF channel: 18.767923486358804 Rsun\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Calculate the median separation \n",
    "# at DCO formation ...\n",
    "#############################################\n",
    "\n",
    "# Some Bools\n",
    "CE_channel   = merging_BBH['CE_Event_Count'] > 0\n",
    "RLOF_channel = merging_BBH['CE_Event_Count'] == 0\n",
    "\n",
    "print('CE systems', np.sum(merging_BBH['mixture_weight'][CE_channel]) )\n",
    "print('stable RLOF systems', np.sum(merging_BBH['mixture_weight'][RLOF_channel]) )\n",
    "\n",
    "#############################################\n",
    "# Helper function to get the weighted median\n",
    "#############################################\n",
    "def weighted_percentile(data, percents, weights=None):\n",
    "    ''' percents in units of 1%\n",
    "        weights specifies the frequency (count) of data.\n",
    "    '''\n",
    "    if weights is None:\n",
    "        return np.percentile(data, percents)\n",
    "    ind=np.argsort(data)\n",
    "    d=data[ind]\n",
    "    w=weights[ind]\n",
    "    p=1.*w.cumsum()/w.sum()*100\n",
    "    y=np.interp(percents, p, d)\n",
    "    return y\n",
    "\n",
    "#############################################\n",
    "# ... for BBHs that merge at z=0\n",
    "#############################################\n",
    "merging_BBH['SemiMajorAxis@DCO_Rsun'] = merging_BBH['SemiMajorAxis@DCO']*u.AU.to(u.Rsun)\n",
    "\n",
    "reduced_weight_z0  = intrinsic_rate_density_z0[rate_nonCHE_bool]\n",
    "median_a_all_z0    = weighted_percentile(merging_BBH['SemiMajorAxis@DCO_Rsun'], 50, weights=reduced_weight_z0)\n",
    "median_a_CE_z0     = weighted_percentile(merging_BBH['SemiMajorAxis@DCO_Rsun'][CE_channel], 50, weights=reduced_weight_z0[CE_channel])\n",
    "median_a_stable_z0 = weighted_percentile(merging_BBH['SemiMajorAxis@DCO_Rsun'][RLOF_channel], 50, weights=reduced_weight_z0[RLOF_channel])\n",
    "    \n",
    "print('\\nWeighted median separation at DCO formation, for BBH merging at z=0: {} Rsun'.format(median_a_all_z0))  \n",
    "print('for CE channel: {} Rsun'.format(median_a_CE_z0))  \n",
    "print('for stable RLOF channel: {} Rsun'.format(median_a_stable_z0))  \n",
    "\n",
    "\n",
    "#############################################\n",
    "# ... for BBH observed by a perfect detector\n",
    "#############################################\n",
    "# Calculate the volume of the fine redshift bins\n",
    "fine_volumes       = cosmo.comoving_volume(redshifts).to(u.Gpc**3).value\n",
    "fine_shell_volumes = np.diff(fine_volumes) #same len in z dimension as weight\n",
    "# centers of redshift bins\n",
    "center_z = (redshifts[:-1] + redshifts[1:])/2.\n",
    "\n",
    "# Convert to number of BBH merging in each shell\n",
    "Rate_perfect_det     = np.sum(intrinsic_rate_density[rate_nonCHE_bool,:] * fine_shell_volumes[:]* 1./(1. + center_z), axis = 1)\n",
    "    \n",
    "median_a_all_allz    = weighted_percentile(merging_BBH['SemiMajorAxis@DCO_Rsun'], 50, weights=Rate_perfect_det)\n",
    "median_a_CE_allz     = weighted_percentile(merging_BBH['SemiMajorAxis@DCO_Rsun'][CE_channel], 50, weights=Rate_perfect_det[CE_channel])\n",
    "median_a_stable_allz = weighted_percentile(merging_BBH['SemiMajorAxis@DCO_Rsun'][RLOF_channel], 50, weights=Rate_perfect_det[RLOF_channel])\n",
    "    \n",
    "print('\\nWeighted median separation at DCO formation, for BBH as detected by a perfect detector {} Rsun'.format(median_a_all_allz))  \n",
    "print('for CE channel: {} Rsun'.format(median_a_CE_allz))  \n",
    "print('for stable RLOF channel: {} Rsun'.format(median_a_stable_allz))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the contribution of sub-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rate observed by perfect detector 191538.8975909716\n",
      "Rate observed by perfect detector for double CE 1168.451087965356\n",
      "this constitutes a fraction:  0.6100333157709644 %\n",
      "stable RLOF constitutes a total fraction:  14.94371548851971 %\n",
      "CE channel constitutes a total fraction:  85.05628451148034 %\n"
     ]
    }
   ],
   "source": [
    "# Some Bools\n",
    "CE_channel        = merging_BBH['CE_Event_Count'] > 0\n",
    "RLOF_channel      = merging_BBH['CE_Event_Count'] == 0\n",
    "\n",
    "two_CE_subchannel = merging_BBH['CE_Event_Count'] > 1\n",
    "\n",
    "R_perfect_det_tot   = np.sum(Rate_perfect_det)\n",
    "print('Total rate observed by perfect detector', np.sum(Rate_perfect_det) )\n",
    "\n",
    "R_perfect_det_twoCE = np.sum(Rate_perfect_det[two_CE_subchannel])\n",
    "print('Rate observed by perfect detector for double CE', R_perfect_det_twoCE )\n",
    "print('this constitutes a fraction: ', R_perfect_det_twoCE/R_perfect_det_tot*100, '%')\n",
    "\n",
    "print('stable RLOF constitutes a total fraction: ', np.sum(Rate_perfect_det[RLOF_channel])/R_perfect_det_tot *100,'%' )\n",
    "print('CE channel constitutes a total fraction: ', np.sum(Rate_perfect_det[CE_channel])/R_perfect_det_tot *100,'%' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many BHs merge with M > 18 Msun vs M < 18 Msun at different redshifts?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_per_crude_bin 10.0\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# centers of redshif bins\n",
    "center_z = (redshifts[:-1] + redshifts[1:])/2.\n",
    "\n",
    "#Centers of your crude redshift bins\n",
    "z_bin_edges = np.array([0,0.5,1,1.5,2])\n",
    "center_Crude_bins = (z_bin_edges[:-1] + z_bin_edges[1:])/2. # center points\n",
    "\n",
    "##############################\n",
    "## Calculate average rate density per z-bin\n",
    "crude_rate_density = get_crude_rate_density(Red_intr_rate_dens, redshifts, z_bin_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rate density of LOW mass BH (< 18 Msun) for $0 < z < 0.5$ 64.48739733653538\n",
      "Average rate density of HIGH mass BH (> 18 Msun) for $0 < z < 0.5$ 44.34506066901206\n",
      "ratio high mass/low mass at low z 0.6876546813882397\n",
      "Average rate density of LOW mass BH (< 18 Msun) for $1.5 < z < 2.0$ 207.1415573901734\n",
      "Average rate density of HIGH mass BH (> 18 Msun) for $1.5 < z < 2.0$ 93.42241751056946\n",
      "ratio high mass/low mass at high z 0.4510076041119952\n",
      "ratio_high_redshift/ratio_low_redshift 1.5247075107351844\n"
     ]
    }
   ],
   "source": [
    "high_mass_end = merging_BBH['M_moreMassive'] > 18\n",
    "low_mass_end = merging_BBH['M_moreMassive'] <= 18\n",
    "\n",
    "\n",
    "\n",
    "R_lowM_lowz = np.sum(crude_rate_density[low_mass_end, 0]) \n",
    "R_highM_lowz = np.sum(crude_rate_density[high_mass_end, 0]) \n",
    "print('Average rate density of LOW mass BH (< 18 Msun) for $0 < z < 0.5$', R_lowM_lowz)\n",
    "print('Average rate density of HIGH mass BH (> 18 Msun) for $0 < z < 0.5$',R_highM_lowz )\n",
    "\n",
    "ratio_low_redshift = R_highM_lowz/R_lowM_lowz\n",
    "print('ratio high mass/low mass at low z', ratio_low_redshift)\n",
    "\n",
    "R_lowM_higherz = np.sum(crude_rate_density[low_mass_end, 3]) \n",
    "R_highM_higherz = np.sum(crude_rate_density[high_mass_end, 3]) \n",
    "print('Average rate density of LOW mass BH (< 18 Msun) for $1.5 < z < 2.0$', R_lowM_higherz)\n",
    "print('Average rate density of HIGH mass BH (> 18 Msun) for $1.5 < z < 2.0$',R_highM_higherz )\n",
    "\n",
    "ratio_high_redshift = R_highM_higherz/R_lowM_higherz\n",
    "print('ratio high mass/low mass at high z', ratio_high_redshift)\n",
    "\n",
    "\n",
    "print('ratio_high_redshift/ratio_low_redshift', ratio_low_redshift/ratio_high_redshift)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
